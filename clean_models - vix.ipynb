{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy_langdetect import LanguageDetector\n",
    "# from spacy.language import Language\n",
    "# import spacy\n",
    "import pandas as pd\n",
    "from frequentist_treatment_nlp import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import regex\n",
    "import re\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense,GRU,LSTM,Embedding, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import SpatialDropout1D,Dropout,Bidirectional,Conv1D,GlobalMaxPooling1D, MaxPooling1D, LeakyReLU, Flatten, InputLayer, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping, History\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/32mor/OneDrive/Documents/Polytechnique/NLP & Natixis/starting_kit/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/32mor/OneDrive/Documents/Polytechnique/NLP & Natixis/starting_kit/data'\n",
    "os.chdir(path)\n",
    "X, y_cat, y_reg = hx.data_expander(all_data=True,index='eur')\n",
    "y = pd.concat([y_cat,y_reg],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_num = numerical_pipeline(ema=True, lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsaved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 415/415 [00:00<00:00, 29637.43it/s]\n",
      "100%|██████████| 1243/1243 [00:00<00:00, 26540.15it/s]\n",
      "100%|██████████| 210/210 [00:00<00:00, 20915.25it/s]\n",
      "100%|██████████| 598/598 [00:00<00:00, 22851.41it/s]\n",
      "100%|██████████| 356/356 [00:00<00:00, 29680.02it/s]\n",
      "100%|██████████| 1050/1050 [00:00<00:00, 27037.10it/s]\n"
     ]
    }
   ],
   "source": [
    "unsaved  = True\n",
    "if unsaved:\n",
    "     print('unsaved')\n",
    "     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "     pipe_ecb = Full_pipeline_nlp('ecb', 0.3, 300,translate=False)\n",
    "     pipe_fed = Full_pipeline_nlp('fed',0.3, 300, translate=False)\n",
    "     pipe_num = numerical_pipeline(ema=True, lstm=True)\n",
    "     test_pipe  = full_pipeline(pipe_fed, pipe_ecb, pipe_num)\n",
    "     X_fed_train, X_ecb_train, X_num_train = test_pipe.fit_transform(X_train)\n",
    "     X_fed_val, X_ecb_val, X_num_val = test_pipe.transform(X_val)\n",
    "     X_fed_test, X_ecb_test, X_num_test = test_pipe.transform(X_test)\n",
    "\n",
    "\n",
    "     y_train_reg = y_train.target_reg\n",
    "     y_train_cat = y_train.target_classif\n",
    "     y_test_reg = y_test.target_reg\n",
    "     y_test_cat = y_test.target_classif\n",
    "     y_val_reg = y_val.target_reg\n",
    "     y_val_cat = y_val.target_classif\n",
    "     os.chdir(path)\n",
    "     saves = [X_fed_train, X_fed_test, X_fed_val, X_ecb_train, X_ecb_test, \n",
    "                    X_ecb_val, X_num_train,X_num_test, X_num_val, y_test_cat,\n",
    "                    y_test_reg, y_train_reg, y_train_cat, y_val_cat, y_val_reg]\n",
    "     for element in saves:\n",
    "          vnames = [name for name in globals() if globals()[name] is element][0]\n",
    "          np.save(f'{vnames}_eurusd.npy',element)\n",
    "\n",
    "else:\n",
    "     print('saved')\n",
    "     for element in os.listdir():\n",
    "          if 'npy' in element :\n",
    "               if element not in ['element.npy','__.npy']:\n",
    "                    str = element\n",
    "                    globals()[str.split('.')[0]] = np.load(element)\n",
    "\n",
    "day_max = 20\n",
    "speeches_train = int(len(X_fed_train)/20)\n",
    "speeches_val = int(len(X_ecb_val)/20)\n",
    "speeches_test = int(len(X_ecb_test)/20)\n",
    "components = 300\n",
    "X_fed_lstm_train = X_fed_train.reshape((speeches_train, day_max, components))\n",
    "X_ecb_lstm_train = X_ecb_train.reshape((speeches_train, day_max, components))\n",
    "X_fed_lstm_test = X_fed_test.reshape((speeches_test, day_max, components))\n",
    "X_ecb_lstm_test = X_ecb_test.reshape((speeches_test, day_max, components))\n",
    "X_fed_lstm_val = X_fed_val.reshape((speeches_val, day_max, components))\n",
    "X_ecb_lstm_val = X_ecb_val.reshape((speeches_val, day_max, components))\n",
    "lstm_shape = (day_max, components)\n",
    "shape_num = day_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_num = (day_max,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_input_output_lstm_full(shape_nlp, shape_num):\n",
    "    input_nlp_fed = Input(shape=(shape_nlp[0], shape_nlp[1]))\n",
    "    input_nlp_bce = Input(shape=(shape_nlp[0], shape_nlp[1]))\n",
    "    input_num = Input(shape=(shape_num[0], shape_num[1]))\n",
    "\n",
    "\n",
    "    w = LSTM(100, return_sequences=True)(input_nlp_fed)\n",
    "    w = Dropout(0.3)(w)\n",
    "    #w = BatchNormalization()(w)\n",
    "    w = LSTM(40, return_sequences=False)(w)\n",
    "    w = Dropout(0.3)(w)\n",
    "    w = Model(inputs=input_nlp_fed, outputs=w)\n",
    "\n",
    "\n",
    "    x = LSTM(100, return_sequences=True)(input_nlp_bce)\n",
    "    x = Dropout(0.3)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = LSTM(40, return_sequences=False)(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Model(inputs=input_nlp_bce, outputs=x)\n",
    "\n",
    "    # the second branch opreates on the second input\n",
    "    y = LSTM(100, return_sequences=False)(input_num)\n",
    "    y = Dropout(0.3)(y)\n",
    "    #y = BatchNormalization()(y)\n",
    "    # y = LSTM(40, return_sequences=False)(y)\n",
    "    # y = Dropout(0.3)(y)\n",
    "    y = Model(inputs=input_num, outputs=y)\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([w.output, x.output, y.output])\n",
    "\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    z = Dropout(0.3)(z)\n",
    "    \n",
    "\n",
    "    out_reg = Dense(1, activation='linear')(z)\n",
    "    \n",
    "\n",
    "    classi = BatchNormalization()(z)\n",
    "    out_class = Dense(1, activation = 'sigmoid')(classi)\n",
    "    model = Model(inputs=[w.input, x.input, y.input], outputs=[out_reg, out_class])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_full(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "    # model = multi_input_output_lstm_full\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model=multi_input_output_lstm_full(lstm_shape, shape_num)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=['mse',tf.keras.losses.binary_crossentropy], \n",
    "                    optimizer=optimizer)\n",
    "\n",
    "    history = model.fit([X_fed_lstm_train, X_ecb_lstm_train, X_num_train], \n",
    "                        [y_train_reg,y_train_cat], \n",
    "                        epochs=50, \n",
    "                        batch_size=128, verbose=2,\n",
    "                        callbacks=[early_stop, tensorboard_callback, ], \n",
    "                        validation_data=([X_fed_lstm_val,X_ecb_lstm_val, X_num_val],[y_val_reg,y_val_cat]))\n",
    "\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate([X_fed_lstm_val,X_ecb_lstm_val, X_num_val],[y_val_reg,y_val_cat], verbose=0)\n",
    "    return score[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:05:06,257]\u001b[0m A new study created in memory with name: no-name-a74bc54d-73a4-4fe4-b47b-48083777fdec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 23s - loss: 1.6017 - dense_1_loss: 0.7553 - dense_2_loss: 0.8463 - val_loss: 1.0597 - val_dense_1_loss: 0.3632 - val_dense_2_loss: 0.6966\n",
      "Epoch 2/50\n",
      "8/8 - 4s - loss: 1.0924 - dense_1_loss: 0.3809 - dense_2_loss: 0.7115 - val_loss: 0.9159 - val_dense_1_loss: 0.2222 - val_dense_2_loss: 0.6937\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.9542 - dense_1_loss: 0.3003 - dense_2_loss: 0.6540 - val_loss: 0.8976 - val_dense_1_loss: 0.2032 - val_dense_2_loss: 0.6944\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.8928 - dense_1_loss: 0.2590 - dense_2_loss: 0.6338 - val_loss: 0.8866 - val_dense_1_loss: 0.1866 - val_dense_2_loss: 0.7000\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 0.8054 - dense_1_loss: 0.2545 - dense_2_loss: 0.5509 - val_loss: 0.8888 - val_dense_1_loss: 0.1830 - val_dense_2_loss: 0.7058\n",
      "Epoch 6/50\n",
      "8/8 - 3s - loss: 0.7533 - dense_1_loss: 0.2516 - dense_2_loss: 0.5017 - val_loss: 0.8814 - val_dense_1_loss: 0.1804 - val_dense_2_loss: 0.7009\n",
      "Epoch 7/50\n",
      "8/8 - 3s - loss: 0.6882 - dense_1_loss: 0.2319 - dense_2_loss: 0.4563 - val_loss: 0.8957 - val_dense_1_loss: 0.1908 - val_dense_2_loss: 0.7050\n",
      "Epoch 8/50\n",
      "8/8 - 3s - loss: 0.6227 - dense_1_loss: 0.2292 - dense_2_loss: 0.3935 - val_loss: 0.9039 - val_dense_1_loss: 0.1886 - val_dense_2_loss: 0.7153\n",
      "Epoch 9/50\n",
      "8/8 - 3s - loss: 0.5260 - dense_1_loss: 0.1972 - dense_2_loss: 0.3288 - val_loss: 0.9391 - val_dense_1_loss: 0.1957 - val_dense_2_loss: 0.7435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:06:17,081]\u001b[0m Trial 0 finished with value: 0.1956726610660553 and parameters: {'learning_rate': 0.0007997737986483937}. Best is trial 0 with value: 0.1956726610660553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 13s - loss: 1.7902 - dense_1_loss: 0.9655 - dense_2_loss: 0.8247 - val_loss: 1.1955 - val_dense_1_loss: 0.5036 - val_dense_2_loss: 0.6919\n",
      "Epoch 2/50\n",
      "8/8 - 2s - loss: 1.1867 - dense_1_loss: 0.4853 - dense_2_loss: 0.7014 - val_loss: 0.9698 - val_dense_1_loss: 0.2690 - val_dense_2_loss: 0.7008\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 1.0437 - dense_1_loss: 0.3280 - dense_2_loss: 0.7158 - val_loss: 0.9585 - val_dense_1_loss: 0.2563 - val_dense_2_loss: 0.7022\n",
      "Epoch 4/50\n",
      "8/8 - 2s - loss: 1.0009 - dense_1_loss: 0.3205 - dense_2_loss: 0.6804 - val_loss: 0.9141 - val_dense_1_loss: 0.2149 - val_dense_2_loss: 0.6992\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 0.9244 - dense_1_loss: 0.2854 - dense_2_loss: 0.6389 - val_loss: 0.8944 - val_dense_1_loss: 0.1960 - val_dense_2_loss: 0.6984\n",
      "Epoch 6/50\n",
      "8/8 - 3s - loss: 0.8893 - dense_1_loss: 0.2671 - dense_2_loss: 0.6222 - val_loss: 0.8832 - val_dense_1_loss: 0.1846 - val_dense_2_loss: 0.6985\n",
      "Epoch 7/50\n",
      "8/8 - 3s - loss: 0.7788 - dense_1_loss: 0.2316 - dense_2_loss: 0.5472 - val_loss: 0.8773 - val_dense_1_loss: 0.1784 - val_dense_2_loss: 0.6989\n",
      "Epoch 8/50\n",
      "8/8 - 3s - loss: 0.7620 - dense_1_loss: 0.2169 - dense_2_loss: 0.5450 - val_loss: 0.8720 - val_dense_1_loss: 0.1755 - val_dense_2_loss: 0.6965\n",
      "Epoch 9/50\n",
      "8/8 - 3s - loss: 0.7316 - dense_1_loss: 0.2386 - dense_2_loss: 0.4930 - val_loss: 0.8663 - val_dense_1_loss: 0.1726 - val_dense_2_loss: 0.6937\n",
      "Epoch 10/50\n",
      "8/8 - 3s - loss: 0.6763 - dense_1_loss: 0.2176 - dense_2_loss: 0.4587 - val_loss: 0.8798 - val_dense_1_loss: 0.1731 - val_dense_2_loss: 0.7066\n",
      "Epoch 11/50\n",
      "8/8 - 3s - loss: 0.6457 - dense_1_loss: 0.2318 - dense_2_loss: 0.4139 - val_loss: 0.8923 - val_dense_1_loss: 0.1822 - val_dense_2_loss: 0.7101\n",
      "Epoch 12/50\n",
      "8/8 - 3s - loss: 0.5903 - dense_1_loss: 0.2070 - dense_2_loss: 0.3833 - val_loss: 0.8923 - val_dense_1_loss: 0.1819 - val_dense_2_loss: 0.7104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:07:03,297]\u001b[0m Trial 1 finished with value: 0.18192340433597565 and parameters: {'learning_rate': 0.0005086025450915318}. Best is trial 0 with value: 0.1956726610660553.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 13s - loss: 1.8195 - dense_1_loss: 0.9873 - dense_2_loss: 0.8322 - val_loss: 1.4906 - val_dense_1_loss: 0.7998 - val_dense_2_loss: 0.6908\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 1.4901 - dense_1_loss: 0.7014 - dense_2_loss: 0.7887 - val_loss: 1.2877 - val_dense_1_loss: 0.5977 - val_dense_2_loss: 0.6900\n",
      "Epoch 3/50\n",
      "8/8 - 2s - loss: 1.3137 - dense_1_loss: 0.5907 - dense_2_loss: 0.7229 - val_loss: 1.1347 - val_dense_1_loss: 0.4425 - val_dense_2_loss: 0.6922\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 1.0984 - dense_1_loss: 0.4245 - dense_2_loss: 0.6738 - val_loss: 1.0191 - val_dense_1_loss: 0.3244 - val_dense_2_loss: 0.6947\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 1.0110 - dense_1_loss: 0.3338 - dense_2_loss: 0.6772 - val_loss: 0.9503 - val_dense_1_loss: 0.2532 - val_dense_2_loss: 0.6971\n",
      "Epoch 6/50\n",
      "8/8 - 2s - loss: 0.9492 - dense_1_loss: 0.2928 - dense_2_loss: 0.6563 - val_loss: 0.9273 - val_dense_1_loss: 0.2286 - val_dense_2_loss: 0.6987\n",
      "Epoch 7/50\n",
      "8/8 - 3s - loss: 0.9468 - dense_1_loss: 0.2871 - dense_2_loss: 0.6597 - val_loss: 0.9219 - val_dense_1_loss: 0.2208 - val_dense_2_loss: 0.7011\n",
      "Epoch 8/50\n",
      "8/8 - 3s - loss: 0.9097 - dense_1_loss: 0.2758 - dense_2_loss: 0.6339 - val_loss: 0.9205 - val_dense_1_loss: 0.2178 - val_dense_2_loss: 0.7027\n",
      "Epoch 9/50\n",
      "8/8 - 3s - loss: 0.9019 - dense_1_loss: 0.2825 - dense_2_loss: 0.6194 - val_loss: 0.9171 - val_dense_1_loss: 0.2129 - val_dense_2_loss: 0.7042\n",
      "Epoch 10/50\n",
      "8/8 - 2s - loss: 0.8481 - dense_1_loss: 0.2542 - dense_2_loss: 0.5939 - val_loss: 0.9149 - val_dense_1_loss: 0.2101 - val_dense_2_loss: 0.7048\n",
      "Epoch 11/50\n",
      "8/8 - 3s - loss: 0.8439 - dense_1_loss: 0.2536 - dense_2_loss: 0.5904 - val_loss: 0.9119 - val_dense_1_loss: 0.2063 - val_dense_2_loss: 0.7056\n",
      "Epoch 12/50\n",
      "8/8 - 3s - loss: 0.8410 - dense_1_loss: 0.2595 - dense_2_loss: 0.5816 - val_loss: 0.9086 - val_dense_1_loss: 0.2028 - val_dense_2_loss: 0.7058\n",
      "Epoch 13/50\n",
      "8/8 - 3s - loss: 0.7867 - dense_1_loss: 0.2421 - dense_2_loss: 0.5446 - val_loss: 0.9109 - val_dense_1_loss: 0.2021 - val_dense_2_loss: 0.7087\n",
      "Epoch 14/50\n",
      "8/8 - 3s - loss: 0.7511 - dense_1_loss: 0.2535 - dense_2_loss: 0.4976 - val_loss: 0.9131 - val_dense_1_loss: 0.1998 - val_dense_2_loss: 0.7133\n",
      "Epoch 15/50\n",
      "8/8 - 2s - loss: 0.7534 - dense_1_loss: 0.2256 - dense_2_loss: 0.5278 - val_loss: 0.9103 - val_dense_1_loss: 0.1962 - val_dense_2_loss: 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:07:56,746]\u001b[0m Trial 2 finished with value: 0.19617411494255066 and parameters: {'learning_rate': 0.00021663305093458883}. Best is trial 2 with value: 0.19617411494255066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 12s - loss: 2.0862 - dense_1_loss: 1.1831 - dense_2_loss: 0.9031 - val_loss: 1.9673 - val_dense_1_loss: 1.2653 - val_dense_2_loss: 0.7019\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 2.0382 - dense_1_loss: 1.1522 - dense_2_loss: 0.8860 - val_loss: 1.9319 - val_dense_1_loss: 1.2302 - val_dense_2_loss: 0.7017\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 1.9886 - dense_1_loss: 1.1185 - dense_2_loss: 0.8701 - val_loss: 1.9010 - val_dense_1_loss: 1.1995 - val_dense_2_loss: 0.7014\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 1.9540 - dense_1_loss: 1.1017 - dense_2_loss: 0.8523 - val_loss: 1.8715 - val_dense_1_loss: 1.1702 - val_dense_2_loss: 0.7012\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 1.9548 - dense_1_loss: 1.1027 - dense_2_loss: 0.8521 - val_loss: 1.8433 - val_dense_1_loss: 1.1422 - val_dense_2_loss: 0.7011\n",
      "Epoch 6/50\n",
      "8/8 - 3s - loss: 1.9388 - dense_1_loss: 1.0743 - dense_2_loss: 0.8645 - val_loss: 1.8156 - val_dense_1_loss: 1.1148 - val_dense_2_loss: 0.7008\n",
      "Epoch 7/50\n",
      "8/8 - 3s - loss: 1.8452 - dense_1_loss: 1.0217 - dense_2_loss: 0.8235 - val_loss: 1.7887 - val_dense_1_loss: 1.0881 - val_dense_2_loss: 0.7006\n",
      "Epoch 8/50\n",
      "8/8 - 3s - loss: 1.8365 - dense_1_loss: 1.0216 - dense_2_loss: 0.8149 - val_loss: 1.7633 - val_dense_1_loss: 1.0630 - val_dense_2_loss: 0.7002\n",
      "Epoch 9/50\n",
      "8/8 - 3s - loss: 1.8266 - dense_1_loss: 1.0065 - dense_2_loss: 0.8201 - val_loss: 1.7393 - val_dense_1_loss: 1.0395 - val_dense_2_loss: 0.6998\n",
      "Epoch 10/50\n",
      "8/8 - 3s - loss: 1.8157 - dense_1_loss: 0.9687 - dense_2_loss: 0.8470 - val_loss: 1.7170 - val_dense_1_loss: 1.0174 - val_dense_2_loss: 0.6995\n",
      "Epoch 11/50\n",
      "8/8 - 2s - loss: 1.7697 - dense_1_loss: 0.9615 - dense_2_loss: 0.8082 - val_loss: 1.6958 - val_dense_1_loss: 0.9966 - val_dense_2_loss: 0.6992\n",
      "Epoch 12/50\n",
      "8/8 - 3s - loss: 1.7402 - dense_1_loss: 0.9221 - dense_2_loss: 0.8181 - val_loss: 1.6739 - val_dense_1_loss: 0.9750 - val_dense_2_loss: 0.6989\n",
      "Epoch 13/50\n",
      "8/8 - 2s - loss: 1.7619 - dense_1_loss: 0.9186 - dense_2_loss: 0.8433 - val_loss: 1.6512 - val_dense_1_loss: 0.9527 - val_dense_2_loss: 0.6985\n",
      "Epoch 14/50\n",
      "8/8 - 3s - loss: 1.7342 - dense_1_loss: 0.9396 - dense_2_loss: 0.7946 - val_loss: 1.6293 - val_dense_1_loss: 0.9308 - val_dense_2_loss: 0.6985\n",
      "Epoch 15/50\n",
      "8/8 - 3s - loss: 1.7257 - dense_1_loss: 0.9149 - dense_2_loss: 0.8108 - val_loss: 1.6083 - val_dense_1_loss: 0.9099 - val_dense_2_loss: 0.6984\n",
      "Epoch 16/50\n",
      "8/8 - 3s - loss: 1.6717 - dense_1_loss: 0.8697 - dense_2_loss: 0.8019 - val_loss: 1.5872 - val_dense_1_loss: 0.8889 - val_dense_2_loss: 0.6983\n",
      "Epoch 17/50\n",
      "8/8 - 3s - loss: 1.6696 - dense_1_loss: 0.8832 - dense_2_loss: 0.7864 - val_loss: 1.5677 - val_dense_1_loss: 0.8693 - val_dense_2_loss: 0.6984\n",
      "Epoch 18/50\n",
      "8/8 - 3s - loss: 1.6477 - dense_1_loss: 0.8699 - dense_2_loss: 0.7778 - val_loss: 1.5471 - val_dense_1_loss: 0.8487 - val_dense_2_loss: 0.6984\n",
      "Epoch 19/50\n",
      "8/8 - 3s - loss: 1.6022 - dense_1_loss: 0.8119 - dense_2_loss: 0.7902 - val_loss: 1.5282 - val_dense_1_loss: 0.8298 - val_dense_2_loss: 0.6984\n",
      "Epoch 20/50\n",
      "8/8 - 2s - loss: 1.6853 - dense_1_loss: 0.8536 - dense_2_loss: 0.8317 - val_loss: 1.5104 - val_dense_1_loss: 0.8122 - val_dense_2_loss: 0.6982\n",
      "Epoch 21/50\n",
      "8/8 - 3s - loss: 1.5473 - dense_1_loss: 0.8049 - dense_2_loss: 0.7423 - val_loss: 1.4899 - val_dense_1_loss: 0.7919 - val_dense_2_loss: 0.6980\n",
      "Epoch 22/50\n",
      "8/8 - 3s - loss: 1.5962 - dense_1_loss: 0.7772 - dense_2_loss: 0.8189 - val_loss: 1.4711 - val_dense_1_loss: 0.7734 - val_dense_2_loss: 0.6978\n",
      "Epoch 23/50\n",
      "8/8 - 3s - loss: 1.5311 - dense_1_loss: 0.7657 - dense_2_loss: 0.7654 - val_loss: 1.4541 - val_dense_1_loss: 0.7565 - val_dense_2_loss: 0.6976\n",
      "Epoch 24/50\n",
      "8/8 - 3s - loss: 1.5675 - dense_1_loss: 0.7778 - dense_2_loss: 0.7897 - val_loss: 1.4380 - val_dense_1_loss: 0.7405 - val_dense_2_loss: 0.6976\n",
      "Epoch 25/50\n",
      "8/8 - 2s - loss: 1.5597 - dense_1_loss: 0.7468 - dense_2_loss: 0.8129 - val_loss: 1.4225 - val_dense_1_loss: 0.7249 - val_dense_2_loss: 0.6976\n",
      "Epoch 26/50\n",
      "8/8 - 3s - loss: 1.5184 - dense_1_loss: 0.7365 - dense_2_loss: 0.7819 - val_loss: 1.4062 - val_dense_1_loss: 0.7088 - val_dense_2_loss: 0.6975\n",
      "Epoch 27/50\n",
      "8/8 - 2s - loss: 1.4818 - dense_1_loss: 0.7134 - dense_2_loss: 0.7684 - val_loss: 1.3914 - val_dense_1_loss: 0.6937 - val_dense_2_loss: 0.6976\n",
      "Epoch 28/50\n",
      "8/8 - 3s - loss: 1.4307 - dense_1_loss: 0.6891 - dense_2_loss: 0.7416 - val_loss: 1.3767 - val_dense_1_loss: 0.6788 - val_dense_2_loss: 0.6979\n",
      "Epoch 29/50\n",
      "8/8 - 3s - loss: 1.4483 - dense_1_loss: 0.6822 - dense_2_loss: 0.7661 - val_loss: 1.3622 - val_dense_1_loss: 0.6642 - val_dense_2_loss: 0.6980\n",
      "Epoch 30/50\n",
      "8/8 - 3s - loss: 1.4624 - dense_1_loss: 0.6721 - dense_2_loss: 0.7903 - val_loss: 1.3486 - val_dense_1_loss: 0.6507 - val_dense_2_loss: 0.6979\n",
      "Epoch 31/50\n",
      "8/8 - 2s - loss: 1.4430 - dense_1_loss: 0.6690 - dense_2_loss: 0.7741 - val_loss: 1.3351 - val_dense_1_loss: 0.6370 - val_dense_2_loss: 0.6981\n",
      "Epoch 32/50\n",
      "8/8 - 3s - loss: 1.4242 - dense_1_loss: 0.6499 - dense_2_loss: 0.7744 - val_loss: 1.3216 - val_dense_1_loss: 0.6235 - val_dense_2_loss: 0.6981\n",
      "Epoch 33/50\n",
      "8/8 - 3s - loss: 1.4496 - dense_1_loss: 0.6652 - dense_2_loss: 0.7845 - val_loss: 1.3086 - val_dense_1_loss: 0.6100 - val_dense_2_loss: 0.6986\n",
      "Epoch 34/50\n",
      "8/8 - 3s - loss: 1.4249 - dense_1_loss: 0.6309 - dense_2_loss: 0.7940 - val_loss: 1.2966 - val_dense_1_loss: 0.5976 - val_dense_2_loss: 0.6990\n",
      "Epoch 35/50\n",
      "8/8 - 3s - loss: 1.3683 - dense_1_loss: 0.6299 - dense_2_loss: 0.7384 - val_loss: 1.2854 - val_dense_1_loss: 0.5859 - val_dense_2_loss: 0.6995\n",
      "Epoch 36/50\n",
      "8/8 - 3s - loss: 1.3609 - dense_1_loss: 0.5974 - dense_2_loss: 0.7635 - val_loss: 1.2726 - val_dense_1_loss: 0.5724 - val_dense_2_loss: 0.7002\n",
      "Epoch 37/50\n",
      "8/8 - 3s - loss: 1.3748 - dense_1_loss: 0.6074 - dense_2_loss: 0.7675 - val_loss: 1.2615 - val_dense_1_loss: 0.5607 - val_dense_2_loss: 0.7008\n",
      "Epoch 38/50\n",
      "8/8 - 3s - loss: 1.3618 - dense_1_loss: 0.5901 - dense_2_loss: 0.7717 - val_loss: 1.2515 - val_dense_1_loss: 0.5502 - val_dense_2_loss: 0.7013\n",
      "Epoch 39/50\n",
      "8/8 - 2s - loss: 1.3073 - dense_1_loss: 0.5813 - dense_2_loss: 0.7261 - val_loss: 1.2411 - val_dense_1_loss: 0.5389 - val_dense_2_loss: 0.7021\n",
      "Epoch 40/50\n",
      "8/8 - 3s - loss: 1.3614 - dense_1_loss: 0.5714 - dense_2_loss: 0.7900 - val_loss: 1.2313 - val_dense_1_loss: 0.5286 - val_dense_2_loss: 0.7027\n",
      "Epoch 41/50\n",
      "8/8 - 2s - loss: 1.3007 - dense_1_loss: 0.5576 - dense_2_loss: 0.7431 - val_loss: 1.2201 - val_dense_1_loss: 0.5172 - val_dense_2_loss: 0.7029\n",
      "Epoch 42/50\n",
      "8/8 - 3s - loss: 1.3175 - dense_1_loss: 0.5557 - dense_2_loss: 0.7618 - val_loss: 1.2104 - val_dense_1_loss: 0.5075 - val_dense_2_loss: 0.7030\n",
      "Epoch 43/50\n",
      "8/8 - 3s - loss: 1.2623 - dense_1_loss: 0.5551 - dense_2_loss: 0.7072 - val_loss: 1.2008 - val_dense_1_loss: 0.4975 - val_dense_2_loss: 0.7034\n",
      "Epoch 44/50\n",
      "8/8 - 3s - loss: 1.3046 - dense_1_loss: 0.5535 - dense_2_loss: 0.7511 - val_loss: 1.1910 - val_dense_1_loss: 0.4874 - val_dense_2_loss: 0.7036\n",
      "Epoch 45/50\n",
      "8/8 - 4s - loss: 1.2415 - dense_1_loss: 0.5110 - dense_2_loss: 0.7304 - val_loss: 1.1824 - val_dense_1_loss: 0.4786 - val_dense_2_loss: 0.7038\n",
      "Epoch 46/50\n",
      "8/8 - 3s - loss: 1.2336 - dense_1_loss: 0.5024 - dense_2_loss: 0.7312 - val_loss: 1.1743 - val_dense_1_loss: 0.4701 - val_dense_2_loss: 0.7042\n",
      "Epoch 47/50\n",
      "8/8 - 3s - loss: 1.2516 - dense_1_loss: 0.5237 - dense_2_loss: 0.7279 - val_loss: 1.1659 - val_dense_1_loss: 0.4616 - val_dense_2_loss: 0.7042\n",
      "Epoch 48/50\n",
      "8/8 - 3s - loss: 1.2364 - dense_1_loss: 0.5030 - dense_2_loss: 0.7334 - val_loss: 1.1590 - val_dense_1_loss: 0.4541 - val_dense_2_loss: 0.7049\n",
      "Epoch 49/50\n",
      "8/8 - 3s - loss: 1.2311 - dense_1_loss: 0.5045 - dense_2_loss: 0.7266 - val_loss: 1.1516 - val_dense_1_loss: 0.4460 - val_dense_2_loss: 0.7056\n",
      "Epoch 50/50\n",
      "8/8 - 3s - loss: 1.2372 - dense_1_loss: 0.5128 - dense_2_loss: 0.7244 - val_loss: 1.1444 - val_dense_1_loss: 0.4382 - val_dense_2_loss: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:10:28,733]\u001b[0m Trial 3 finished with value: 0.4381687045097351 and parameters: {'learning_rate': 1.4576432019147325e-05}. Best is trial 3 with value: 0.4381687045097351.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 4\n",
      "Best trial:\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_full, n_trials=4, timeout=None)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    learning_rate: 1.4576432019147325e-05\n"
     ]
    }
   ],
   "source": [
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    learning_rate = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=multi_input_output_lstm_full(lstm_shape, shape_num)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(loss=['mse',tf.keras.losses.binary_crossentropy], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 - 16s - loss: 2.1561 - dense_4_loss: 1.2660 - dense_5_loss: 0.8902 - val_loss: 2.0176 - val_dense_4_loss: 1.3321 - val_dense_5_loss: 0.6855\n",
      "Epoch 2/50\n",
      "4/4 - 3s - loss: 2.0602 - dense_4_loss: 1.2154 - dense_5_loss: 0.8449 - val_loss: 1.9943 - val_dense_4_loss: 1.3088 - val_dense_5_loss: 0.6855\n",
      "Epoch 3/50\n",
      "4/4 - 3s - loss: 2.0785 - dense_4_loss: 1.1856 - dense_5_loss: 0.8930 - val_loss: 1.9720 - val_dense_4_loss: 1.2865 - val_dense_5_loss: 0.6855\n",
      "Epoch 4/50\n",
      "4/4 - 3s - loss: 2.0557 - dense_4_loss: 1.1816 - dense_5_loss: 0.8741 - val_loss: 1.9508 - val_dense_4_loss: 1.2653 - val_dense_5_loss: 0.6855\n",
      "Epoch 5/50\n",
      "4/4 - 3s - loss: 2.0015 - dense_4_loss: 1.1196 - dense_5_loss: 0.8819 - val_loss: 1.9299 - val_dense_4_loss: 1.2444 - val_dense_5_loss: 0.6855\n",
      "Epoch 6/50\n",
      "4/4 - 4s - loss: 1.9764 - dense_4_loss: 1.1321 - dense_5_loss: 0.8444 - val_loss: 1.9089 - val_dense_4_loss: 1.2235 - val_dense_5_loss: 0.6855\n",
      "Epoch 7/50\n",
      "4/4 - 3s - loss: 2.0222 - dense_4_loss: 1.1455 - dense_5_loss: 0.8766 - val_loss: 1.8884 - val_dense_4_loss: 1.2029 - val_dense_5_loss: 0.6855\n",
      "Epoch 8/50\n",
      "4/4 - 3s - loss: 1.9673 - dense_4_loss: 1.1108 - dense_5_loss: 0.8565 - val_loss: 1.8682 - val_dense_4_loss: 1.1827 - val_dense_5_loss: 0.6855\n",
      "Epoch 9/50\n",
      "4/4 - 3s - loss: 1.9321 - dense_4_loss: 1.0820 - dense_5_loss: 0.8501 - val_loss: 1.8488 - val_dense_4_loss: 1.1633 - val_dense_5_loss: 0.6855\n",
      "Epoch 10/50\n",
      "4/4 - 3s - loss: 1.9346 - dense_4_loss: 1.0548 - dense_5_loss: 0.8798 - val_loss: 1.8296 - val_dense_4_loss: 1.1442 - val_dense_5_loss: 0.6854\n",
      "Epoch 11/50\n",
      "4/4 - 3s - loss: 1.9049 - dense_4_loss: 1.0716 - dense_5_loss: 0.8333 - val_loss: 1.8110 - val_dense_4_loss: 1.1256 - val_dense_5_loss: 0.6854\n",
      "Epoch 12/50\n",
      "4/4 - 2s - loss: 1.8603 - dense_4_loss: 1.0138 - dense_5_loss: 0.8464 - val_loss: 1.7929 - val_dense_4_loss: 1.1076 - val_dense_5_loss: 0.6853\n",
      "Epoch 13/50\n",
      "4/4 - 2s - loss: 1.8708 - dense_4_loss: 1.0162 - dense_5_loss: 0.8546 - val_loss: 1.7753 - val_dense_4_loss: 1.0901 - val_dense_5_loss: 0.6853\n",
      "Epoch 14/50\n",
      "4/4 - 2s - loss: 1.8191 - dense_4_loss: 1.0282 - dense_5_loss: 0.7909 - val_loss: 1.7579 - val_dense_4_loss: 1.0727 - val_dense_5_loss: 0.6852\n",
      "Epoch 15/50\n",
      "4/4 - 2s - loss: 1.8585 - dense_4_loss: 1.0016 - dense_5_loss: 0.8569 - val_loss: 1.7411 - val_dense_4_loss: 1.0559 - val_dense_5_loss: 0.6852\n",
      "Epoch 16/50\n",
      "4/4 - 2s - loss: 1.8310 - dense_4_loss: 0.9919 - dense_5_loss: 0.8391 - val_loss: 1.7248 - val_dense_4_loss: 1.0396 - val_dense_5_loss: 0.6852\n",
      "Epoch 17/50\n",
      "4/4 - 2s - loss: 1.7882 - dense_4_loss: 0.9555 - dense_5_loss: 0.8326 - val_loss: 1.7091 - val_dense_4_loss: 1.0239 - val_dense_5_loss: 0.6852\n",
      "Epoch 18/50\n",
      "4/4 - 3s - loss: 1.7941 - dense_4_loss: 0.9760 - dense_5_loss: 0.8182 - val_loss: 1.6933 - val_dense_4_loss: 1.0081 - val_dense_5_loss: 0.6852\n",
      "Epoch 19/50\n",
      "4/4 - 3s - loss: 1.8152 - dense_4_loss: 0.9672 - dense_5_loss: 0.8479 - val_loss: 1.6777 - val_dense_4_loss: 0.9924 - val_dense_5_loss: 0.6852\n",
      "Epoch 20/50\n",
      "4/4 - 3s - loss: 1.7464 - dense_4_loss: 0.9339 - dense_5_loss: 0.8126 - val_loss: 1.6623 - val_dense_4_loss: 0.9770 - val_dense_5_loss: 0.6852\n",
      "Epoch 21/50\n",
      "4/4 - 3s - loss: 1.7551 - dense_4_loss: 0.9323 - dense_5_loss: 0.8228 - val_loss: 1.6472 - val_dense_4_loss: 0.9619 - val_dense_5_loss: 0.6853\n",
      "Epoch 22/50\n",
      "4/4 - 3s - loss: 1.7538 - dense_4_loss: 0.9100 - dense_5_loss: 0.8438 - val_loss: 1.6323 - val_dense_4_loss: 0.9470 - val_dense_5_loss: 0.6853\n",
      "Epoch 23/50\n",
      "4/4 - 3s - loss: 1.7594 - dense_4_loss: 0.8884 - dense_5_loss: 0.8711 - val_loss: 1.6175 - val_dense_4_loss: 0.9323 - val_dense_5_loss: 0.6853\n",
      "Epoch 24/50\n",
      "4/4 - 3s - loss: 1.7330 - dense_4_loss: 0.9076 - dense_5_loss: 0.8254 - val_loss: 1.6034 - val_dense_4_loss: 0.9182 - val_dense_5_loss: 0.6852\n",
      "Epoch 25/50\n",
      "4/4 - 3s - loss: 1.6607 - dense_4_loss: 0.8792 - dense_5_loss: 0.7815 - val_loss: 1.5894 - val_dense_4_loss: 0.9041 - val_dense_5_loss: 0.6852\n",
      "Epoch 26/50\n",
      "4/4 - 3s - loss: 1.6831 - dense_4_loss: 0.8727 - dense_5_loss: 0.8105 - val_loss: 1.5756 - val_dense_4_loss: 0.8903 - val_dense_5_loss: 0.6853\n",
      "Epoch 27/50\n",
      "4/4 - 3s - loss: 1.6421 - dense_4_loss: 0.8576 - dense_5_loss: 0.7845 - val_loss: 1.5622 - val_dense_4_loss: 0.8769 - val_dense_5_loss: 0.6854\n",
      "Epoch 28/50\n",
      "4/4 - 3s - loss: 1.6550 - dense_4_loss: 0.8653 - dense_5_loss: 0.7897 - val_loss: 1.5490 - val_dense_4_loss: 0.8636 - val_dense_5_loss: 0.6854\n",
      "Epoch 29/50\n",
      "4/4 - 3s - loss: 1.6421 - dense_4_loss: 0.8346 - dense_5_loss: 0.8075 - val_loss: 1.5356 - val_dense_4_loss: 0.8502 - val_dense_5_loss: 0.6854\n",
      "Epoch 30/50\n",
      "4/4 - 2s - loss: 1.6339 - dense_4_loss: 0.8439 - dense_5_loss: 0.7900 - val_loss: 1.5228 - val_dense_4_loss: 0.8373 - val_dense_5_loss: 0.6855\n",
      "Epoch 31/50\n",
      "4/4 - 3s - loss: 1.6226 - dense_4_loss: 0.8276 - dense_5_loss: 0.7951 - val_loss: 1.5106 - val_dense_4_loss: 0.8251 - val_dense_5_loss: 0.6855\n",
      "Epoch 32/50\n",
      "4/4 - 2s - loss: 1.5741 - dense_4_loss: 0.8053 - dense_5_loss: 0.7688 - val_loss: 1.4985 - val_dense_4_loss: 0.8130 - val_dense_5_loss: 0.6856\n",
      "Epoch 33/50\n",
      "4/4 - 3s - loss: 1.5883 - dense_4_loss: 0.7753 - dense_5_loss: 0.8130 - val_loss: 1.4862 - val_dense_4_loss: 0.8006 - val_dense_5_loss: 0.6856\n",
      "Epoch 34/50\n",
      "4/4 - 2s - loss: 1.5824 - dense_4_loss: 0.7942 - dense_5_loss: 0.7882 - val_loss: 1.4741 - val_dense_4_loss: 0.7886 - val_dense_5_loss: 0.6855\n",
      "Epoch 35/50\n",
      "4/4 - 3s - loss: 1.5319 - dense_4_loss: 0.7541 - dense_5_loss: 0.7777 - val_loss: 1.4622 - val_dense_4_loss: 0.7767 - val_dense_5_loss: 0.6855\n",
      "Epoch 36/50\n",
      "4/4 - 3s - loss: 1.5589 - dense_4_loss: 0.7710 - dense_5_loss: 0.7880 - val_loss: 1.4502 - val_dense_4_loss: 0.7648 - val_dense_5_loss: 0.6854\n",
      "Epoch 37/50\n",
      "4/4 - 3s - loss: 1.5321 - dense_4_loss: 0.7584 - dense_5_loss: 0.7737 - val_loss: 1.4385 - val_dense_4_loss: 0.7532 - val_dense_5_loss: 0.6853\n",
      "Epoch 38/50\n",
      "4/4 - 2s - loss: 1.5065 - dense_4_loss: 0.7183 - dense_5_loss: 0.7882 - val_loss: 1.4269 - val_dense_4_loss: 0.7416 - val_dense_5_loss: 0.6853\n",
      "Epoch 39/50\n",
      "4/4 - 2s - loss: 1.4911 - dense_4_loss: 0.7243 - dense_5_loss: 0.7668 - val_loss: 1.4153 - val_dense_4_loss: 0.7300 - val_dense_5_loss: 0.6853\n",
      "Epoch 40/50\n",
      "4/4 - 2s - loss: 1.4966 - dense_4_loss: 0.7292 - dense_5_loss: 0.7674 - val_loss: 1.4040 - val_dense_4_loss: 0.7188 - val_dense_5_loss: 0.6852\n",
      "Epoch 41/50\n",
      "4/4 - 2s - loss: 1.4513 - dense_4_loss: 0.7092 - dense_5_loss: 0.7420 - val_loss: 1.3930 - val_dense_4_loss: 0.7077 - val_dense_5_loss: 0.6853\n",
      "Epoch 42/50\n",
      "4/4 - 3s - loss: 1.5089 - dense_4_loss: 0.7400 - dense_5_loss: 0.7689 - val_loss: 1.3822 - val_dense_4_loss: 0.6970 - val_dense_5_loss: 0.6853\n",
      "Epoch 43/50\n",
      "4/4 - 3s - loss: 1.4701 - dense_4_loss: 0.6945 - dense_5_loss: 0.7755 - val_loss: 1.3714 - val_dense_4_loss: 0.6861 - val_dense_5_loss: 0.6853\n",
      "Epoch 44/50\n",
      "4/4 - 3s - loss: 1.4388 - dense_4_loss: 0.6907 - dense_5_loss: 0.7481 - val_loss: 1.3606 - val_dense_4_loss: 0.6755 - val_dense_5_loss: 0.6852\n",
      "Epoch 45/50\n",
      "4/4 - 2s - loss: 1.4576 - dense_4_loss: 0.6920 - dense_5_loss: 0.7656 - val_loss: 1.3499 - val_dense_4_loss: 0.6648 - val_dense_5_loss: 0.6851\n",
      "Epoch 46/50\n",
      "4/4 - 3s - loss: 1.3959 - dense_4_loss: 0.6345 - dense_5_loss: 0.7613 - val_loss: 1.3392 - val_dense_4_loss: 0.6541 - val_dense_5_loss: 0.6851\n",
      "Epoch 47/50\n",
      "4/4 - 2s - loss: 1.4057 - dense_4_loss: 0.6539 - dense_5_loss: 0.7518 - val_loss: 1.3289 - val_dense_4_loss: 0.6439 - val_dense_5_loss: 0.6850\n",
      "Epoch 48/50\n",
      "4/4 - 3s - loss: 1.3855 - dense_4_loss: 0.6562 - dense_5_loss: 0.7294 - val_loss: 1.3184 - val_dense_4_loss: 0.6334 - val_dense_5_loss: 0.6850\n",
      "Epoch 49/50\n",
      "4/4 - 2s - loss: 1.3674 - dense_4_loss: 0.6393 - dense_5_loss: 0.7280 - val_loss: 1.3085 - val_dense_4_loss: 0.6235 - val_dense_5_loss: 0.6850\n",
      "Epoch 50/50\n",
      "4/4 - 3s - loss: 1.3629 - dense_4_loss: 0.6321 - dense_5_loss: 0.7308 - val_loss: 1.2982 - val_dense_4_loss: 0.6132 - val_dense_5_loss: 0.6850\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_fed_lstm_train, X_ecb_lstm_train, X_num_train], [y_train_reg,y_train_cat], epochs=50, batch_size=256, verbose=2,\n",
    "         callbacks=[early_stop, tensorboard_callback, ], \n",
    "         validation_data=([X_fed_lstm_val,X_ecb_lstm_val, X_num_val],[y_val_reg,y_val_cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.298182725906372, 0.6132282018661499, 0.6849546432495117]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_fed_lstm_val,X_ecb_lstm_val, X_num_val],[y_val_reg,y_val_cat], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mutli_inouts_outputs_model_eurusd\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mutli_inouts_outputs_model_eurusd\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mutli_inouts_outputs_model_eurusd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_input_class_lstm_full(shape_nlp, shape_num):\n",
    "    input_nlp_fed = Input(shape=(shape_nlp[0], shape_nlp[1]))\n",
    "    input_nlp_bce = Input(shape=(shape_nlp[0], shape_nlp[1]))\n",
    "    input_num = Input(shape=shape_num)\n",
    "\n",
    "\n",
    "    w = LSTM(100, return_sequences=True)(input_nlp_fed)\n",
    "    w = Dropout(0.3)(w)\n",
    "    #w = BatchNormalization()(w)\n",
    "    w = LSTM(40, return_sequences=False)(w)\n",
    "    w = Dropout(0.3)(w)\n",
    "    w = Model(inputs=input_nlp_fed, outputs=w)\n",
    "\n",
    "\n",
    "    x = LSTM(100, return_sequences=True)(input_nlp_bce)\n",
    "    x = Dropout(0.3)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = LSTM(40, return_sequences=False)(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Model(inputs=input_nlp_bce, outputs=x)\n",
    "\n",
    "    # the second branch opreates on the second input\n",
    "    y = LSTM(100, return_sequences=False)(input_num)\n",
    "    y = Dropout(0.3)(y)\n",
    "    #y = BatchNormalization()(y)\n",
    "    # y = LSTM(40, return_sequences=False)(y)\n",
    "    # y = Dropout(0.3)(y)\n",
    "    y = Model(inputs=input_num, outputs=y)\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([w.output, x.output, y.output])\n",
    "\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    z = Dropout(0.3)(z)\n",
    "    classi = BatchNormalization()(z)\n",
    "    classi = Dense(64)(classi)\n",
    "    classi = LeakyReLU(0.3)(classi)\n",
    "    classi = Dropout(0.5)(classi)\n",
    "    z = Dense(64, activation='relu')(z)\n",
    "    z = Dropout(0.3)(z)\n",
    "    out_reg = Dense(1, activation='linear')(z)\n",
    "    \n",
    "    out_class = Dense(1, activation = 'sigmoid')(z)\n",
    "    model = Model(inputs=[w.input, x.input, y.input], outputs=out_class)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_class(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model=multi_input_class_lstm_full(lstm_shape, shape_num)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy, \n",
    "                    optimizer=optimizer)\n",
    "\n",
    "    history = model.fit([X_fed_lstm_train, X_ecb_lstm_train, X_num_train], \n",
    "                        y_train_cat,\n",
    "                        epochs=50, \n",
    "                        batch_size=128, verbose=2,\n",
    "                        callbacks=[early_stop, tensorboard_callback, ], \n",
    "                        validation_data=([X_fed_lstm_val,X_ecb_lstm_val, X_num_val],y_val_cat))\n",
    "\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    y_pred = model.predict([X_fed_lstm_test,X_ecb_lstm_test, X_num_test])\n",
    "    score = accuracy_score(y_test_cat, (y_pred)>=0.5)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:42:26,212]\u001b[0m A new study created in memory with name: no-name-d29fea1d-47ac-4863-9da9-5045ac6b6b79\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 14s - loss: 0.7065 - val_loss: 0.6912\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6937 - val_loss: 0.7211\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6863 - val_loss: 0.7823\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6860 - val_loss: 0.7066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:42:55,068]\u001b[0m Trial 0 finished with value: 0.5537848605577689 and parameters: {'learning_rate': 0.013049696474121502}. Best is trial 0 with value: 0.5537848605577689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 14s - loss: 0.6894 - val_loss: 0.7019\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6717 - val_loss: 0.7082\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6581 - val_loss: 0.7003\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6331 - val_loss: 0.7240\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 0.5500 - val_loss: 0.8024\n",
      "Epoch 6/50\n",
      "8/8 - 3s - loss: 0.4491 - val_loss: 1.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:43:28,735]\u001b[0m Trial 1 finished with value: 0.5378486055776892 and parameters: {'learning_rate': 0.0012744188353801748}. Best is trial 0 with value: 0.5537848605577689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 13s - loss: 0.6820 - val_loss: 0.7054\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6790 - val_loss: 0.6987\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6641 - val_loss: 0.6964\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6566 - val_loss: 0.6906\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 0.6481 - val_loss: 0.6931\n",
      "Epoch 6/50\n",
      "8/8 - 3s - loss: 0.6259 - val_loss: 0.6939\n",
      "Epoch 7/50\n",
      "8/8 - 2s - loss: 0.5926 - val_loss: 0.7132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:44:03,374]\u001b[0m Trial 2 finished with value: 0.5537848605577689 and parameters: {'learning_rate': 0.0006421828924535239}. Best is trial 0 with value: 0.5537848605577689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 14s - loss: 0.6985 - val_loss: 0.6915\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6856 - val_loss: 0.7229\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6807 - val_loss: 0.6959\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6303 - val_loss: 0.8052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:44:31,735]\u001b[0m Trial 3 finished with value: 0.5856573705179283 and parameters: {'learning_rate': 0.0047346144099486035}. Best is trial 3 with value: 0.5856573705179283.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 4\n",
      "Best trial:\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_class, n_trials=4, timeout=None)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Value: 0.5856573705179283\n",
      "  Params: \n",
      "    learning_rate: 0.0047346144099486035\n"
     ]
    }
   ],
   "source": [
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    learning_rate = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 17s - loss: 0.7038 - val_loss: 0.6964\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6823 - val_loss: 0.6907\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6683 - val_loss: 0.6884\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6084 - val_loss: 0.9618\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 0.4827 - val_loss: 0.9019\n",
      "Epoch 6/50\n",
      "8/8 - 3s - loss: 0.4098 - val_loss: 1.0448\n"
     ]
    }
   ],
   "source": [
    "model_cat=multi_input_class_lstm_full(lstm_shape, shape_num)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model_cat.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=optimizer)\n",
    "history = model_cat.fit([X_fed_lstm_train, X_ecb_lstm_train, X_num_train], y_train_cat, epochs=50, batch_size=128, verbose=2,\n",
    "    validation_data = ([X_fed_lstm_val, X_ecb_lstm_val, X_num_val], y_val_cat), callbacks=[early_stop, tensorboard_callback, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_inputs_class_model_eurusd\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_inputs_class_model_eurusd\\assets\n"
     ]
    }
   ],
   "source": [
    "model_cat.save(\"multi_inputs_class_model_eurusd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_input_reg_lstm_full(shape_nlp, shape_num):\n",
    "    input_nlp_fed = Input(shape=(shape_nlp[0], shape_nlp[1]))\n",
    "    input_nlp_bce = Input(shape=(shape_nlp[0], shape_nlp[1]))\n",
    "    input_num = Input(shape=shape_num)\n",
    "\n",
    "\n",
    "    w = LSTM(100, return_sequences=True)(input_nlp_fed)\n",
    "    w = Dropout(0.3)(w)\n",
    "    #w = BatchNormalization()(w)\n",
    "    w = LSTM(40, return_sequences=False)(w)\n",
    "    w = Dropout(0.3)(w)\n",
    "    w = Model(inputs=input_nlp_fed, outputs=w)\n",
    "\n",
    "\n",
    "    x = LSTM(100, return_sequences=True)(input_nlp_bce)\n",
    "    x = Dropout(0.3)(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = LSTM(40, return_sequences=False)(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Model(inputs=input_nlp_bce, outputs=x)\n",
    "\n",
    "    # the second branch opreates on the second input\n",
    "    y = LSTM(100, return_sequences=False)(input_num)\n",
    "    y = Dropout(0.3)(y)\n",
    "    #y = BatchNormalization()(y)\n",
    "    # y = LSTM(40, return_sequences=False)(y)\n",
    "    # y = Dropout(0.3)(y)\n",
    "    y = Model(inputs=input_num, outputs=y)\n",
    "    # combine the output of the two branches\n",
    "    combined = concatenate([w.output, x.output, y.output])\n",
    "\n",
    "    z = Dense(64, activation='relu')(combined)\n",
    "    z = Dropout(0.3)(z)\n",
    "    # classi = BatchNormalization()(z)\n",
    "    # classi = Dense(64)(classi)\n",
    "    # classi = LeakyReLU(0.3)(classi)\n",
    "    # classi = Dropout(0.5)(classi)\n",
    "    z = Dense(64, activation='relu')(z)\n",
    "    z = Dropout(0.3)(z)\n",
    "    out_reg = Dense(1, activation='linear')(z)\n",
    "    \n",
    "    # out_class = Dense(1, activation = 'sigmoid')(z)\n",
    "    model = Model(inputs=[w.input, x.input, y.input], outputs=out_reg)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_reg(trial):\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model=multi_input_reg_lstm_full(lstm_shape, shape_num)\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=['mse'], \n",
    "                    optimizer=optimizer)\n",
    "\n",
    "    history = model.fit([X_fed_lstm_train, X_ecb_lstm_train, X_num_train], \n",
    "                        y_train_reg, \n",
    "                        epochs=50, \n",
    "                        batch_size=128, verbose=2,\n",
    "                        callbacks=[early_stop, tensorboard_callback, ], \n",
    "                        validation_data=([X_fed_lstm_val,X_ecb_lstm_val, X_num_val],y_val_reg))\n",
    "\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    y_pred = model.predict([X_fed_lstm_test,X_ecb_lstm_test, X_num_test])\n",
    "    score = mean_squared_error(y_test_reg, y_pred)**(1/2)\n",
    "    return -score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:45:44,918]\u001b[0m A new study created in memory with name: no-name-bc23b58a-a762-404b-ac76-4f829ae06ec3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 18s - loss: 0.6833 - val_loss: 0.6984\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6768 - val_loss: 0.6941\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6699 - val_loss: 0.6978\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6541 - val_loss: 0.7143\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 0.6263 - val_loss: 0.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:46:20,305]\u001b[0m Trial 0 finished with value: 0.5617529880478087 and parameters: {'learning_rate': 0.0009633256677424558}. Best is trial 0 with value: 0.5617529880478087.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 16s - loss: 3.1618 - val_loss: 0.7401\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.7455 - val_loss: 0.7226\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.7237 - val_loss: 0.7037\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.7035 - val_loss: 0.7010\n",
      "Epoch 5/50\n",
      "8/8 - 3s - loss: 0.6870 - val_loss: 0.6982\n",
      "Epoch 6/50\n",
      "8/8 - 3s - loss: 0.6947 - val_loss: 0.6962\n",
      "Epoch 7/50\n",
      "8/8 - 3s - loss: 0.6890 - val_loss: 0.6986\n",
      "Epoch 8/50\n",
      "8/8 - 2s - loss: 0.6864 - val_loss: 0.6988\n",
      "Epoch 9/50\n",
      "8/8 - 2s - loss: 0.6850 - val_loss: 0.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:47:03,373]\u001b[0m Trial 1 finished with value: 0.5657370517928287 and parameters: {'learning_rate': 0.09360889900063225}. Best is trial 1 with value: 0.5657370517928287.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 20s - loss: 0.6978 - val_loss: 0.6940\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6890 - val_loss: 0.6956\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6839 - val_loss: 0.6962\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6766 - val_loss: 0.6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:47:36,797]\u001b[0m Trial 2 finished with value: 0.5657370517928287 and parameters: {'learning_rate': 0.0002386596872395553}. Best is trial 1 with value: 0.5657370517928287.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 13s - loss: 0.6921 - val_loss: 0.6960\n",
      "Epoch 2/50\n",
      "8/8 - 3s - loss: 0.6839 - val_loss: 0.6982\n",
      "Epoch 3/50\n",
      "8/8 - 3s - loss: 0.6755 - val_loss: 0.6999\n",
      "Epoch 4/50\n",
      "8/8 - 3s - loss: 0.6702 - val_loss: 0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-28 22:48:04,213]\u001b[0m Trial 3 finished with value: 0.5697211155378487 and parameters: {'learning_rate': 0.0004007283356744439}. Best is trial 3 with value: 0.5697211155378487.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 4\n",
      "Best trial:\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective_class, n_trials=4, timeout=None)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "    learning_rate = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg=multi_input_reg_lstm_full(lstm_shape, shape_num)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model_reg.compile(loss=['mse'], optimizer=optimizer)\n",
    "history = model_reg.fit([X_fed_lstm_train, X_ecb_lstm_train, X_num_train], y_train_reg, epochs=50, batch_size=128, verbose=0,\n",
    "    validation_data = ([X_fed_lstm_val, X_ecb_lstm_val, X_num_val], y_val_reg), callbacks=[early_stop, tensorboard_callback, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x211e8e56b50>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_inputs_reg_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_inputs_reg_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_reg.save(\"multi_inputs_reg_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 20, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(902, 20, 300)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fed_lstm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4482039670720707"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test_reg, model_reg.predict([X_fed_lstm_test, X_ecb_lstm_test, X_num_test]))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/32mor/OneDrive/Documents/Polytechnique/NLP & Natixis/starting_kit/answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_expander(\n",
    "    index='vix', task='classification', test_size=0, \n",
    "    price_data=True, speech_data = True, all_data=False,\n",
    "    validation = False):\n",
    "    \n",
    "    if index == 'vix':\n",
    "        df = pd.read_json('./data/test/VIX_1w.json')\n",
    "    else: \n",
    "        df = pd.read_json('./data/test/EURUSDV1M_1w.json')\n",
    "    \n",
    "    # Creation of a df with all the input variables \n",
    "\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "\n",
    "    prices = pd.DataFrame(\n",
    "            df['stock'].to_list(),\n",
    "            columns=['price' + str(i) for i in range(1,21)]\n",
    "            )\n",
    "\n",
    "    speeches = pd.DataFrame(df['speech'].values.tolist())\n",
    "    speech_cols = pd.DataFrame(index=speeches.index)\n",
    "\n",
    "    for i in range(len(speeches.columns)):\n",
    "        daily = pd.DataFrame(speeches[i].values.tolist())\n",
    "        daily.columns = [f'ecb{i+1}', f'fed{i+1}']\n",
    "        speech_cols = speech_cols.join(daily)\n",
    "\n",
    "    speech_cols = speech_cols.applymap(unpack)\n",
    "\n",
    "    if price_data:\n",
    "        X = X.join(prices)\n",
    "    if speech_data:\n",
    "        X = X.join(speech_cols)\n",
    "    \n",
    "    # Target variable\n",
    "\n",
    "    if task == 'classification':\n",
    "        y = df['target_classif']\n",
    "    else:\n",
    "        y = df['target_reg']\n",
    "\n",
    "    # Return entire frame\n",
    "\n",
    "    if all_data:\n",
    "        return X, df['target_classif'], df['target_reg']\n",
    "\n",
    "    # Validation data, stay away\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    if validation:\n",
    "        return X_train, X_validation, y_train, y_validation\n",
    "\n",
    "    # Train-test split\n",
    "    \n",
    "    if test_size > 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_train, y_train, test_size=test_size, random_state=1)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/32mor/OneDrive/Documents/Polytechnique/NLP & Natixis/starting_kit/data'\n",
    "os.chdir(path)\n",
    "X, y_cat, y_reg = hx.data_expander(all_data=True,index='eur')\n",
    "y = pd.concat([y_cat,y_reg],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:00<00:00, 18129.87it/s]\n",
      "100%|██████████| 1262/1262 [00:00<00:00, 15389.97it/s]\n"
     ]
    }
   ],
   "source": [
    "X_fed_test_final, X_ecb_test_final, X_num_test_final = test_pipe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_test = int(len(X_ecb_test_final)/20)\n",
    "components = 300\n",
    "X_fed_lstm_test_final = X_fed_test_final.reshape((speeches_test, day_max, components))\n",
    "X_ecb_lstm_test_final = X_ecb_test_final.reshape((speeches_test, day_max, components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_cat_eurusd = model_cat.predict([X_fed_lstm_test_final, X_ecb_lstm_test_final, X_num_test_final])\n",
    "y_final_reg_eurusd = model_reg.predict([X_fed_lstm_test_final, X_ecb_lstm_test_final, X_num_test_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\32mor\\\\OneDrive\\\\Documents\\\\Polytechnique\\\\NLP & Natixis\\\\starting_kit\\\\data\\\\answers'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('answers')\n",
    "os.chdir('answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('VIX_1w')\n",
    "os.mkdir('EURUSDV1M_1w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('./VIX_1w/pred_reg.txt', vix_reg, fmt='%.3f')\n",
    "# np.savetxt('./VIX_1w/pred_classif.txt', vix_class, fmt='%d')\n",
    "np.savetxt('./EURUSDV1M_1w/pred_reg.txt', y_final_reg_eurusd, fmt='%.3f')\n",
    "np.savetxt('./EURUSDV1M_1w/pred_classif.txt', y_final_cat_eurusd, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cef52191e58c18720989589d5b4ea8cc9868f5ede1a0d5b620ab4c0f06813bfa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
